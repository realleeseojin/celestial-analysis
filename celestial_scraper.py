import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import time


# ============================================================
# 1. SEDS Messier Catalog ìŠ¤í¬ë˜í•‘
# ============================================================

def scrape_seds_messier():
    """
    SEDS ì›¹ì‚¬ì´íŠ¸ì—ì„œ Messier ì²œì²´ ëª©ë¡ ìˆ˜ì§‘
    http://www.messier.seds.org/dataRA.html
    """
    url = "http://www.messier.seds.org/dataRA.html"
    
    print("=" * 60)
    print("ğŸ”­ SEDS Messier Catalog ìˆ˜ì§‘ ì‹œì‘")
    print(f"ğŸ“¡ URL: {url}")
    print("=" * 60)
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        # BeautifulSoup íŒŒì‹±
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # <pre> íƒœê·¸ ì•ˆì˜ ë°ì´í„° ì¶”ì¶œ
        pre_tag = soup.find('pre')
        
        if pre_tag:
            raw_text = pre_tag.get_text()
            return parse_seds_data(raw_text)
        else:
            print("âš ï¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def parse_seds_data(raw_text):
    """SEDS ë°ì´í„° íŒŒì‹±"""
    
    # ì²œì²´ ì¢…ë¥˜ ì½”ë“œ ë§¤í•‘
    type_mapping = {
        '1': 'Open Cluster',       # ì‚°ê°œì„±ë‹¨
        '2': 'Globular Cluster',   # êµ¬ìƒì„±ë‹¨
        '3': 'Planetary Nebula',   # í–‰ì„±ìƒ ì„±ìš´
        '4': 'Diffuse Nebula',     # ë°œê´‘/ë°˜ì‚¬ ì„±ìš´
        '5': 'Spiral Galaxy',      # ë‚˜ì„  ì€í•˜
        '6': 'Elliptical Galaxy',  # íƒ€ì› ì€í•˜
        '7': 'Irregular Galaxy',   # ë¶ˆê·œì¹™ ì€í•˜
        '8': 'Lenticular Galaxy',  # ë Œì¦ˆí˜• ì€í•˜
        '9': 'Supernova Remnant',  # ì´ˆì‹ ì„± ì”í•´
        'A': 'Asterism',           # ì„±êµ°
        'B': 'Milky Way Patch',    # ì€í•˜ìˆ˜ ì˜ì—­
        'C': 'Binary Star'         # ì´ì¤‘ì„±
    }
    
    # ëŒ€ë¶„ë¥˜ ë§¤í•‘
    category_mapping = {
        'Open Cluster': 'ì„±ë‹¨', 'Globular Cluster': 'ì„±ë‹¨',
        'Planetary Nebula': 'ì„±ìš´', 'Diffuse Nebula': 'ì„±ìš´', 'Supernova Remnant': 'ì„±ìš´',
        'Spiral Galaxy': 'ì€í•˜', 'Elliptical Galaxy': 'ì€í•˜', 
        'Irregular Galaxy': 'ì€í•˜', 'Lenticular Galaxy': 'ì€í•˜',
        'Asterism': 'ê¸°íƒ€', 'Milky Way Patch': 'ê¸°íƒ€', 'Binary Star': 'ê¸°íƒ€'
    }
    
    objects = []
    lines = raw_text.strip().split('\n')
    
    for line in lines:
        line = line.strip()
        if not line or not line.startswith('M'):
            continue
        
        parts = line.split()
        if len(parts) < 11:
            continue
            
        try:
            m_number = parts[0]
            ngc_number = parts[1]
            constellation = parts[2]
            type_code = parts[3]
            
            # RA (ì ê²½)
            ra_h, ra_m = parts[4], parts[5]
            ra_decimal = float(ra_h) + float(ra_m) / 60
            
            # Dec (ì ìœ„)
            dec_d, dec_m = parts[6], parts[7]
            dec_val = dec_d.replace('+', '')
            dec_sign = -1 if '-' in dec_d else 1
            dec_decimal = dec_sign * (abs(float(dec_val)) + float(dec_m) / 60)
            
            # ë°ê¸°, í¬ê¸°, ê±°ë¦¬
            magnitude = float(parts[8])
            size = parts[9]
            distance = parts[10] if len(parts) > 10 else None
            
            obj_type = type_mapping.get(type_code, 'Unknown')
            category = category_mapping.get(obj_type, 'ê¸°íƒ€')
            
            objects.append({
                'messier': m_number,
                'ngc': ngc_number,
                'constellation': constellation,
                'type_code': type_code,
                'object_type': obj_type,
                'category': category,
                'ra_h': float(ra_h),
                'ra_m': float(ra_m),
                'ra_decimal': round(ra_decimal, 4),
                'dec_d': float(dec_val) * dec_sign,
                'dec_m': float(dec_m),
                'dec_decimal': round(dec_decimal, 4),
                'magnitude': magnitude,
                'size': size,
                'distance_kly': distance
            })
            
        except (ValueError, IndexError):
            continue
    
    print(f"âœ… {len(objects)}ê°œ ì²œì²´ ìˆ˜ì§‘ ì™„ë£Œ")
    return pd.DataFrame(objects)


# ============================================================
# 2. Wikipedia Messier Objects ìŠ¤í¬ë˜í•‘
# ============================================================

def scrape_wikipedia_messier():
    """
    Wikipediaì—ì„œ Messier ì²œì²´ ëª©ë¡ ìˆ˜ì§‘
    https://en.wikipedia.org/wiki/List_of_Messier_objects
    """
    url = "https://en.wikipedia.org/wiki/List_of_Messier_objects"
    
    print("\n" + "=" * 60)
    print("ğŸ“š Wikipedia Messier ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘")
    print(f"ğŸ“¡ URL: {url}")
    print("=" * 60)
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # wikitable í´ë˜ìŠ¤ í…Œì´ë¸” ì°¾ê¸°
        tables = soup.find_all('table', {'class': 'wikitable'})
        
        for table in tables:
            rows = table.find_all('tr')
            if len(rows) > 100:  # Messier ëª©ë¡ í…Œì´ë¸” (110ê°œ + í—¤ë”)
                return parse_wikipedia_table(table)
        
        print("âš ï¸ ì ì ˆí•œ í…Œì´ë¸”ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def parse_wikipedia_table(table):
    """Wikipedia í…Œì´ë¸” íŒŒì‹±"""
    
    rows = table.find_all('tr')
    objects = []
    
    for row in rows[1:]:  # í—¤ë” ì œì™¸
        cells = row.find_all(['td', 'th'])
        
        if len(cells) >= 8:
            try:
                # ê° ì…€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                messier = cells[0].get_text(strip=True)
                ngc = cells[1].get_text(strip=True)
                common_name = cells[2].get_text(strip=True)
                obj_type = cells[3].get_text(strip=True)
                distance_ly = cells[4].get_text(strip=True)
                constellation = cells[5].get_text(strip=True)
                magnitude = cells[6].get_text(strip=True)
                
                # ì´ë¯¸ì§€ ì…€ì´ ìˆëŠ” ê²½ìš°
                if len(cells) >= 9:
                    ra = cells[7].get_text(strip=True)
                    dec = cells[8].get_text(strip=True)
                else:
                    ra, dec = '', ''
                
                objects.append({
                    'messier': messier,
                    'ngc': ngc,
                    'common_name': common_name,
                    'object_type': obj_type,
                    'distance': distance_ly,
                    'constellation': constellation,
                    'magnitude': magnitude,
                    'ra': ra,
                    'dec': dec
                })
                
            except Exception:
                continue
    
    print(f"âœ… {len(objects)}ê°œ ì²œì²´ ìˆ˜ì§‘ ì™„ë£Œ")
    return pd.DataFrame(objects)


# ============================================================
# 3. NGC ì¹´íƒˆë¡œê·¸ ìŠ¤í¬ë˜í•‘ (ì¶”ê°€ ë°ì´í„°)
# ============================================================

def scrape_ngc_catalog():
    """
    Wikipedia NGC ì¹´íƒˆë¡œê·¸ ì¼ë¶€ ìˆ˜ì§‘
    """
    url = "https://en.wikipedia.org/wiki/List_of_NGC_objects"
    
    print("\n" + "=" * 60)
    print("ğŸŒŒ NGC Catalog ìˆ˜ì§‘ ì‹œì‘")
    print(f"ğŸ“¡ URL: {url}")
    print("=" * 60)
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ëª¨ë“  í…Œì´ë¸”ì—ì„œ NGC ë°ì´í„° ì¶”ì¶œ
        tables = soup.find_all('table', {'class': 'wikitable'})
        
        all_objects = []
        for table in tables:
            rows = table.find_all('tr')
            for row in rows[1:]:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 4:
                    try:
                        ngc = cells[0].get_text(strip=True)
                        obj_type = cells[1].get_text(strip=True)
                        constellation = cells[2].get_text(strip=True)
                        
                        all_objects.append({
                            'ngc': ngc,
                            'object_type': obj_type,
                            'constellation': constellation
                        })
                    except:
                        continue
        
        print(f"âœ… {len(all_objects)}ê°œ NGC ì²œì²´ ìˆ˜ì§‘ ì™„ë£Œ")
        return pd.DataFrame(all_objects)
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


# ============================================================
# 4. ë°ì´í„° ì •ì œ í•¨ìˆ˜
# ============================================================

def clean_data(df):
    """ìˆ˜ì§‘ëœ ë°ì´í„° ì •ì œ"""
    
    if df is None or df.empty:
        return None
    
    # ê±°ë¦¬ ìˆ«ì ë³€í™˜
    if 'distance_kly' in df.columns:
        df['distance_kly'] = pd.to_numeric(df['distance_kly'], errors='coerce')
    
    # í¬ê¸° í‰ê· ê°’ ê³„ì‚° (ì˜ˆ: "17x10" -> 13.5)
    if 'size' in df.columns:
        def parse_size(s):
            if pd.isna(s):
                return None
            s = str(s)
            if 'x' in s.lower():
                parts = re.split(r'[xX]', s)
                try:
                    return (float(parts[0]) + float(parts[1])) / 2
                except:
                    return None
            try:
                return float(s)
            except:
                return None
        
        df['size_arcmin'] = df['size'].apply(parse_size)
    
    return df


def save_data(df, filename):
    """CSV íŒŒì¼ë¡œ ì €ì¥"""
    df.to_csv(filename, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {filename}")
    print(f"   - {len(df)}ê°œ ë ˆì½”ë“œ")
    print(f"   - ì»¬ëŸ¼: {list(df.columns)}")


# ============================================================
# 5. ë©”ì¸ ì‹¤í–‰
# ============================================================

def main():
    print("\n" + "ğŸŒŸ" * 25)
    print("  ì²œì²´ ê´€ì¸¡ ë°ì´í„° ìˆ˜ì§‘ (BeautifulSoup)")
    print("ğŸŒŸ" * 25 + "\n")
    
    # 1. SEDS Messier ìˆ˜ì§‘
    seds_df = scrape_seds_messier()
    if seds_df is not None:
        seds_df = clean_data(seds_df)
        save_data(seds_df, 'messier_seds.csv')
    
    # 2. Wikipedia Messier ìˆ˜ì§‘
    wiki_df = scrape_wikipedia_messier()
    if wiki_df is not None:
        save_data(wiki_df, 'messier_wikipedia.csv')
    
    # 3. NGC ì¹´íƒˆë¡œê·¸ ìˆ˜ì§‘ (ì„ íƒ)
    # ngc_df = scrape_ngc_catalog()
    # if ngc_df is not None:
    #     save_data(ngc_df, 'ngc_catalog.csv')
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    
    if seds_df is not None:
        print("\n[ì²œì²´ ëŒ€ë¶„ë¥˜ë³„ ê°œìˆ˜]")
        print(seds_df['category'].value_counts())
        print("\n[ì²œì²´ ì„¸ë¶€ ì¢…ë¥˜ë³„ ê°œìˆ˜]")
        print(seds_df['object_type'].value_counts())
        print("\n[ë°ê¸°(ë“±ê¸‰) í†µê³„]")
        print(seds_df['magnitude'].describe())
    
    return seds_df, wiki_df


if __name__ == "__main__":
    seds_data, wiki_data = main()
